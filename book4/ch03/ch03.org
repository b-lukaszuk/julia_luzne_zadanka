#+TITLE: Ch03. Distributions
#+STARTUP: overview
#+STARTUP: indent
#+OPTIONS: \n: t

* Link to the chapter online
[[https://allendowney.github.io/ThinkBayes2/chap03.html][Chapter 3]]

* Warning
*The content of this file may be incorrect, erroneous and/or harmful. Use it at Your own risk.*

* Data Files
none yet
* Environment

#+BEGIN_SRC

println("Let's go.")

#+END_SRC

#+BEGIN_SRC

cd(joinpath(homedir(), "Desktop", "julia/luzne_zadanka/book4/ch03")

#+END_SRC

#+BEGIN_SRC

using Pkg
Pkg.activate(".")
Pkg.status()

#+END_SRC

* Imports

#+BEGIN_SRC

import DataFrames as Dfs

#+END_SRC

* Pmf
** struct definition

#+BEGIN_SRC

len(collection) = length(collection)

mutable struct Pmf{T}
    names::Vector{T} # names of hypotheses
    priors::Vector{Flt} # priors for each hypothesis
    likelihoods::Vector{Flt} # likelihoods for each hypothesis
    posteriors::Vector{Flt} # posteriors for each hypothesis

    Pmf(ns::Vector{Int}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Int}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )

    Pmf(ns::Vector{Flt}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Flt}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )

    Pmf(ns::Vector{Str}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Str}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )
end

function getFirstN(v::Vec{A}, n::Int)::Str where A<:Union{Flt, Int, Str}
    @assert 0 < n <= 10 "n must be in range [1-10]"
    vv::Vec{A} = first(v, n)
    vv = eltype(v) == Flt ? round.(vv, digits=3) : vv
    result::Str = join(string.(vv), ", ")
    return len(v) > n ? result * "..." : result
end

function Base.show(io::IO, pmf::Pmf)
    result::Str = "names: $(getFirstN(pmf.names, 10))\n"
    result = result * "priors: $(getFirstN(pmf.priors, 10))\n"
    result = result * "likelihoods: $(getFirstN(pmf.likelihoods, 10))\n"
    result = result * "posteriors: $(getFirstN(pmf.posteriors, 10))\n"
    print(io, result)
    return nothing
end

#+END_SRC

** helper fns

#+BEGIN_SRC

function pmf2df(pmf::Pmf{T})::Dfs.DataFrame where {T}
    return Dfs.DataFrame(
        (;
        names=pmf.names,
        priors=pmf.priors,
        likelihoods=pmf.likelihoods,
        posteriors=pmf.posteriors
         )
    )
end

function getCounts(v::Vector{T})::Dict{T,Int} where {T}
    result::Dict{T,Int} = Dict()
    for elt in v
        result[elt] = get(result, elt, 0) + 1
    end
    return result
end

function getPmfFromSeq(seq::Vector{T})::Pmf{T} where {T}
    counts::Dict{T,Int} = getCounts(seq)
    sortedKeys::Vector{T} = keys(counts) |> collect |> sort
    sortedVals::Vector{Int} = [counts[k] for k in sortedKeys]
    return Pmf(sortedKeys, sortedVals)
end

function getFieldValsEqName(pmf::Pmf{T}, name::T, fieldName::String, default) where {T}
    ind = findfirst(x -> x == name, getproperty(pmf, Symbol("names")))
    return isnothing(ind) ? default : getproperty(pmf, Symbol(fieldName))[ind]
end

function getPriorByName(pmf::Pmf{T}, name::T)::Float64 where {T}
    return getFieldValsEqName(pmf, name, "priors", 0.0)
end

function getPriorsByNames(pmf::Pmf{T}, names::Vector{T})::Vector{Float64} where {T}
    return map(n -> getPriorByName(pmf, n), names)
end

function setLikelihoods!(pmf::Pmf{T}, newLikelihoods::Vector{Float64})::Pmf{T} where {T}
    pmf.likelihoods = newLikelihoods
    return pmf
end

function setPosteriors!(pmf::Pmf{T}, newPosteriors::Vector{Float64})::Pmf{T} where {T}
    pmf.posteriors = newPosteriors
    return pmf
end

"""
        normalizes pmf.posteriors so they add up to 1
"""
function normalizePosteriors!(pmf::Pmf{T})::Pmf{T} where {T}
    pmf.posteriors = pmf.posteriors ./ sum(pmf.posteriors)
    return pmf
end

"""
        updates posteriors (priors .* likeliehoods)
        if normalize = true, then posteriors are normalized
"""
function bayesUpdate!(pmf::Pmf{T}, normalize::Bool)::Pmf{T} where {T}
    setPosteriors!(pmf, pmf.priors .* pmf.likelihoods)
    if normalize
        normalizePosteriors!(pmf)
    end
    return pmf
end

function getIndMaxField(pmf::Pmf, field::String)::Int
    maxProb::Float64 = max(getproperty(pmf, Symbol(field))...)
    return findfirst(x -> x == maxProb, getproperty(pmf, Symbol(field)))
end

function getIndMaxPosterior(pmf::Pmf)::Int
    return getIndMaxField(pmf, "posteriors")
end

function getIndMaxPrior(pmf::Pmf)::Int
    return getIndMaxField(pmf, "priors")
end

function getNameMaxPrior(pmf::Pmf{T})::T where {T}
    return pmf.names[getIndMaxPrior(pmf)]
end

function getNameMaxPosterior(pmf::Pmf{T})::T where {T}
    return pmf.names[getIndMaxPosterior(pmf)]
end

function updatePosteriors!(pmf::Pmf{<:Union{Flt, Int}},
                           nameThatOccurred::Union{Flt, Int})::Pmf{<:Union{Flt, Int}}
    hypos::Vec{<:Union{Flt, Int}} = pmf.names
    likelihoods::Vec{Flt} = 1 ./ hypos
    impossible::Bv = nameThatOccurred .> hypos
    likelihoods[impossible] .= 0.0
    setLikelihoods!(pmf, likelihoods)
    if all(pmf.posteriors .== 0) # posteriors are initialized with 0s
        return bayesUpdate!(pmf, true)
    else
        pmf.posteriors .*= pmf.likelihoods
        return normalizePosteriors!(pmf)
    end
end

#+END_SRC

** other fns

#+BEGIN_SRC

function rep(x::A, times::Int)::Vec{A} where A
    @assert times > 1 "times must be greater than 1"
    return [x for _ in 1:times]
end

function rep(v::Vector{A}, times::Vector{Int})::Vector{A} where A
    @assert (len(v) == len(times)) "length(v) not equal length(times)"
    @assert all(map((>)(0), times)) "times elts must be GT 0"
    result::Vector{A} = Vec{eltype(v)}(undef, sum(times))
    currInd::Int = 1
    for i in eachindex(v)
        for _ in 1:times[i]
            result[currInd] = v[i]
            currInd += 1
        end
    end
    return result
end

c(sth) = collect(sth)
str(sth) = string(sth)

#+END_SRC

* 3.1. Distributions

a distribution - a set of possible outcomes and their corresponding probabilities

* 3.2. Probability Mass Functions

PMF - maps each possible outcome to its probability (for discrete distributions).

#+BEGIN_SRC

coin = Pmf(["heads", "tails"], rep(1/2, 2))
coin |> pmf2df

#+END_SRC

#+BEGIN_SRC

die = getPmfFromSeq(c(1:6))
die |> pmf2df

#+END_SRC

#+BEGIN_SRC

letters = getPmfFromSeq(str.(c("Mississippi")))
letters |> pmf2df

#+END_SRC

#+BEGIN_SRC

getPriorByName(letters, "s")
getPriorByName(letters, "t")

#+END_SRC


#+BEGIN_SRC

getPriorsByNames(die, [1, 4, 7])

#+END_SRC

* 3.3. The Cookie Problem Revisited

There are 2 bowls of cookies:

- Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.
- Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.

You choose a bowl at random and choose a cookie from it. The cookie is vanilla.
What is the probability that it came from Bowl1?

#+BEGIN_SRC

cookies = getPmfFromSeq(["Bowl 1", "Bowl 2"])
cookies |> pmf2df

#+END_SRC

#+BEGIN_SRC

setLikelihoods!(cookies, [30/40, 20/40]) |> pmf2df

#+END_SRC

#+BEGIN_SRC

bayesUpdate!(cookies, true) |> pmf2df

#+END_SRC

You put the cookie back to the bowl and draw again from the same bowl.
The second cookie is also vanilla. What are the posteriors now?

#+BEGIN_SRC

cookies.posteriors .*= cookies.likelihoods
normalizePosteriors!(cookies) |> pmf2df

#+END_SRC

We do the same thing again, but this time we get a chocolate cookie.
What are the posteriors now?

#+BEGIN_SRC

setLikelihoods!(cookies, [10/40, 20/40])
cookies.posteriors .*= cookies.likelihoods
normalizePosteriors!(cookies) |> pmf2df

#+END_SRC

* 3.4. 101 Bowls

Cookie problem with 101 Bowls (vanilla and/or chocolate cookies):

- Bowl 1 contains 0% vanilla cookies,
- Bowl 2 contains 1% vanilla cookies,
- Bowl 99 contains 99% vanilla cookies,
- Bowl 100 contains 100% vanilla cookies,

You choose a bowl at random and choose a cookie from it. The cookie is vanilla.
What is the probability that it came from Bowl x?

#+BEGIN_SRC

bowls101 = getPmfFromSeq(c(0:100))
bowls101.likelihoods = bowls101.names ./ 100
bayesUpdate!(bowls101)

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1],
              title="Posterior after one vanilla cookie",
              xlabel="Bowl #", ylabel="PMF",
              xticks=(0:20:100), yticks=(0:0.0025:0.02)
              );
Cmk.lines!(ax, bowls101.names, bowls101.posteriors, color=:blue, label="posterior");
Cmk.lines!(ax, bowls101.names, bowls101.priors, color=:gray, label="prior");
Cmk.axislegend(position=:lt)
fig

#+END_SRC

Now we put the cookie back, and draw again. This time vanilla cookie (again).
What are the posteriors?

#+BEGIN_SRC

bowls101.posteriors .*= bowls101.likelihoods
normalizePosteriors!(bowls101)

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1],
              title="Posterior after two vanilla cookie",
              xlabel="Bowl #", ylabel="PMF",
              xticks=(0:20:100), yticks=(0:0.005:0.03)
              );
Cmk.lines!(ax, bowls101.names, bowls101.posteriors, color=:blue, label="posterior");
Cmk.lines!(ax, bowls101.names, bowls101.priors, color=:gray, label="prior");
Cmk.axislegend(position=:lt)
fig

#+END_SRC

How about we put the cookie back and draw again. This time we got chocolate cookie.
What are the posteriors?

#+BEGIN_SRC

bowls101.likelihoods = (100 .- bowls101.names) ./ 100
bowls101.posteriors .*= bowls101.likelihoods
normalizePosteriors!(bowls101)

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1],
              title="Posterior after 2 vanilla, 1 chocolate cookie",
              xlabel="Bowl #", ylabel="PMF",
              xticks=(0:20:100), yticks=(0:0.0025:0.0175)
              );
Cmk.lines!(ax, bowls101.names, bowls101.posteriors, color=:blue, label="posterior");
Cmk.lines!(ax, bowls101.names, bowls101.priors, color=:gray, label="prior");
Cmk.axislegend(position=:lt)
fig

#+END_SRC

Let's see where is the maximum posterior probability (for which hypothesis, which of 101 bowls).

#+BEGIN_SRC

getIndMaxPosterior(bowls101) # 1 indexed
getNameMaxPosterior(bowls101)

df = bowls101 |> pmf2df
df[getIndMaxPosterior(bowls101), :]

#+END_SRC

* 3.5. The Dice Problem

You got three dice: 6-, 8-, and 12-sided die. You choose one at random, roll it, get 1.
What are the posteriors?

#+BEGIN_SRC

dice = getPmfFromSeq([6, 8, 12])
dice.likelihoods = [1/nSides for nSides in dice.names]
bayesUpdate!(dice)
dice

#+END_SRC

Now, you roll again and get 7. What are the posteriors?

#+BEGIN_SRC

dice.likelihoods = [0, 1/8, 1/12]
dice.posteriors .= dice.likelihoods .* dice.posteriors
normalizePosteriors!(dice)
dice

#+END_SRC

* 3.6. Updating Dice

The same problem, but we will write the function to automate the calculations
from 3.5 (see `updatePosteriors!` above).

#+BEGIN_SRC

dice = getPmfFromSeq([6, 8, 12])
updatePosteriors!(dice, 1)
updatePosteriors!(dice, 7)
dice

#+END_SRC
