{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785d88c2-f64d-412c-8d6c-56ba7ded9a06",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Chapter 9. Decision Analysis\n",
    "\n",
    "[Link to chapter online](https://allendowney.github.io/ThinkBayes2/chap09.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ad01a-e10d-446f-bd52-a8eb2181db84",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Warning\n",
    "\n",
    "The content of this file may be incorrect, erroneous and/or harmful. Use it at Your own risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75d72d-b671-4abc-90de-2426c7524c2b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce4f5f-1d19-4fb0-a0ea-6605be6cc3cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "include(\"./pmfAndCdf.jl\")\n",
    "include(\"./simplestat.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CairoMakie as Cmk\n",
    "import CSV as Csv\n",
    "import DataFrames as Dfs\n",
    "import Distributions as Dsts\n",
    "import KernelDensity as Kde\n",
    "import Statistics as Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = Union{Int,Float64} # custom type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f1073-ab2e-43dc-a8e8-20df8a32a2be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## The Price is Right Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87f49f4-23be-4dbf-bd3b-ee0fb8b94d1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*The Price is Right* - a gameshow. The objective is to guess the price of a collection of prizes.\n",
    "The contestant who comes closest to the actual price, without going over, wins the prizes.\n",
    "\n",
    "One of the episodes, two contestants (N and L):\n",
    "- N Prize: dishwasher, wine cabinet, laptop, car.\n",
    "- L Prize: pinball machine, video arcade game, pool table, cruise of the Bahamas\n",
    "\n",
    "Bids:\n",
    "- N: $26'000 (real price: $25'347, diff: $653)\n",
    "- L: $21'500 (real price: $21'578, diff: $78)\n",
    "\n",
    "L wins her showcase, and due to smaller diffs also N showcase.\n",
    "\n",
    "Several questions for a Bayesian thinker.\n",
    "\n",
    "1. Before seeing the prizes, what prior beliefs should the contestants have about the price of the showcase?\n",
    "2. After seeing the prizes, how should the contestants update those beliefs?\n",
    "3. Based on the posterior distribution, what should the contestants bid?\n",
    "\n",
    "Problem inspired by Cameron Davidson-Pilon's [book](https://dataorigami.net/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Prior\n",
    "\n",
    "To choose the prior distribution we can use the track of previous prices.\n",
    "See [the book repo.](https://github.com/AllenDowney/ThinkBayes2/tree/master/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_data(filename::String):: Dfs.DataFrame\n",
    "    df = Csv.read(filename, Dfs.DataFrame; header=false, skipto=4) \n",
    "    df = Dfs.dropmissing(df)\n",
    "    df = Dfs.permutedims(df, 1)\n",
    "    df[!, 2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011 = read_data(\"./showcases2011.csv\")\n",
    "df2012 = read_data(\"./showcases2012.csv\")\n",
    "df = vcat(df2011, df2012)\n",
    "first(df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two columns, `Showcase 1` and `Showcase 2`, are the values of the\n",
    "showcases in dollars. The next two columns are the bids the contestants made.\n",
    "The last two columns are the differences between the actual values and the bids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "We can use this sample to estimate the prior distribution of showcase prices, e.g. using KDE, i.e. [kernel density estimation](https://mathisonian.github.io/kde/).\n",
    "\n",
    "More info on used [KDE library in Julia](https://github.com/JuliaStats/KernelDensity.jl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getKDEfromSample(sample::Vector{A}, qs::Vector{B}) where {A<:Num, B<:Num}\n",
    "    # optional keyword argument is kernel (defaults to Dsts.Normal)\n",
    "    gaussianKde::Kde.KernelDensity.UnivariateKDE = Kde.kde(sample) \n",
    "    ps::Vector{Float64} = Kde.pdf(gaussianKde, qs)\n",
    "    pmf::Pmf{B} = Pmf(qs, ps)\n",
    "    return pmf\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = range(0, 80000, 81) |> collect\n",
    "prior1 = getKDEfromSample(df[!, \"Showcase 1\"], qs)\n",
    "prior2 = getKDEfromSample(df[!, \"Showcase 2\"], qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = Cmk.Figure()\n",
    "ax1, l1 = Cmk.lines(\n",
    "    fig[1, 1],\n",
    "    prior1.names, prior1.priors,\n",
    "    color=:blue, linewidth=3,\n",
    "    axis=(;title=\"Prior distribution of showcase value\",\n",
    "    xlabel=\"Showcase value in \\$\", ylabel=\"PMF\",\n",
    "    xticks=(0:10000:80000, map(x -> string(x, \"k\"), 0:10:80)),\n",
    "    yticks=0:0.01:0.06, \n",
    "    )\n",
    "\n",
    ")\n",
    "l2 = Cmk.lines!(\n",
    "    fig[1, 1],\n",
    "    prior2.names, prior2.priors,\n",
    "    color=:orange, linewidth=3,\n",
    ")\n",
    "Cmk.axislegend(\n",
    "    ax1,\n",
    "    [l1, l2],\n",
    "    [\"Showcase 1\", \"Showcase 2\"]\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Error\n",
    "\n",
    "To update the priors we need to know:\n",
    "- What data should we consider and how should we quantify it?\n",
    "- Can we compute a likelihood function; that is, for each hypothetical price,\n",
    "can we compute the conditional likelihood of the data?\n",
    "\n",
    "\n",
    "[...] model each contestant as a price-guessing instrument with known error characteristics.\n",
    "\n",
    "Now the question we have to answer is, “If the actual price is price, what is the likelihood that the contestant’s guess would be guess?”\n",
    "\n",
    "Equivalently, if we define `error = guess - price`, we can ask, “What is the likelihood that the contestant’s guess is off by `error`?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDiff1 = df[:, \"Bid 1\"] .- df[:, \"Showcase 1\"]\n",
    "sampleDiff2 = df[:, \"Bid 2\"] .- df[:, \"Showcase 2\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = range(-40000, 20000, 61) |> collect\n",
    "kdeDiff1 = getKDEfromSample(sampleDiff1, qs)\n",
    "kdeDiff2 = getKDEfromSample(sampleDiff2, qs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = Cmk.Figure()\n",
    "ax1, l1 = Cmk.lines(\n",
    "    fig[1, 1],\n",
    "    kdeDiff1.names, kdeDiff1.priors,\n",
    "    color=:blue, linewidth=3,\n",
    "    axis=(;title=\"Difference between bid and actual value\",\n",
    "    xlabel=\"Difference in value in \\$\", ylabel=\"PMF\",\n",
    "    xticks=(-40000:10000:20000, map(x -> string(x, \"k\"), -40:10:20)),\n",
    "    yticks=0:0.01:0.07, \n",
    "    )\n",
    "\n",
    ")\n",
    "l2 = Cmk.lines!(\n",
    "    fig[1, 1],\n",
    "    kdeDiff2.names, kdeDiff2.priors,\n",
    "    color=:orange, linewidth=3,\n",
    ")\n",
    "Cmk.axislegend(\n",
    "    ax1,\n",
    "    [l1, l2],\n",
    "    [\"Diff 1\", \"Diff 2\"]\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like these distributions are well modeled by a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanDiff1 = Stats.mean(sampleDiff1)\n",
    "stdDiff1 = Stats.std(sampleDiff1)\n",
    "\n",
    "(meanDiff1, stdDiff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the diffs to model distribution of errors.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- contestants underbid because they are being strategic, and that on average their guesses are accurate. In other words, the mean of their errors is 0.\n",
    "- the spread of the differences reflects the actual spread of their errors. So, the standard deviation of the differences is the standard deviation of their errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorDist1 = Dsts.Normal(0, stdDiff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can, e.g. calculate the probablity density of `error=-100` for Player 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dsts.pdf(errorDist1, -100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By itself, this number doesn’t mean very much, because probability densities are not probabilities. But they are proportional to probabilities, so we can use them as likelihoods in a Bayesian update [...]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  },
  "name": "ch09.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
