#+TITLE: Ch04. Estimating Proportions
#+STARTUP: overview
#+STARTUP: indent
#+OPTIONS: \n: t

* Link to the chapter online
[[https://allendowney.github.io/ThinkBayes2/chap04.html][Chapter 4]]

* Warning
*The content of this file may be incorrect, erroneous and/or harmful. Use it at Your own risk.*

* Environment

#+BEGIN_SRC

println("Let's go.")

#+END_SRC

#+BEGIN_SRC

cd(joinpath(homedir(), "Desktop", "julia/luzne_zadanka/book4/ch04")

#+END_SRC

#+BEGIN_SRC

using Pkg
Pkg.activate(".")
Pkg.status()

#+END_SRC

* Imports

#+BEGIN_SRC

import CairoMakie as Cmk
import DataFrames as Dfs
import Distributions as Dst

#+END_SRC

* Pmf
** struct definition

#+BEGIN_SRC

len(collection) = length(collection)

mutable struct Pmf{T}
    names::Vec{T} # names of hypotheses
    priors::Vec{Flt} # priors for each hypothesis
    likelihoods::Vec{Flt} # likelihoods for each hypothesis
    posteriors::Vec{Flt} # posteriors for each hypothesis

    Pmf(ns::Vec{Int}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Int}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )

    Pmf(ns::Vec{Flt}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Flt}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )

    Pmf(ns::Vec{Str}, prs) =
        (len(ns) != len(prs)) ?
        error("length(names) must be equal length(priors)") :
        new{Str}(
            ns, (prs ./ sum(prs)), zeros(len(ns)), zeros(len(ns))
        )
end

function round3(x::Flt)::Flt
    return round(x, digits=3)
end

function getFirstN(v::Vec{A}, n::Int)::Str where A<:Union{Flt, Int, Str}
    @assert 0 < n <= 10 "n must be in range [1-10]"
    vv::Vec{A} = first(v, n)
    vv = eltype(v) == Flt ? round3.(vv) : vv
    result::Str = join(string.(vv), ", ")
    return len(v) > n ? result * "..." : result
end

function Base.show(io::IO, pmf::Pmf)
    result::Str = "names: $(getFirstN(pmf.names, 10))\n"
    result = result * "priors: $(getFirstN(pmf.priors, 10))\n"
    result = result * "likelihoods: $(getFirstN(pmf.likelihoods, 10))\n"
    result = result * "posteriors: $(getFirstN(pmf.posteriors, 10))\n"
    print(io, result)
    return nothing
end

#+END_SRC

** helper fns

#+BEGIN_SRC

function pmf2df(pmf::Pmf{T})::Dfs.DataFrame where {T}
    return Dfs.DataFrame(
        (;
        names=pmf.names,
        priors=pmf.priors,
        likelihoods=pmf.likelihoods,
        posteriors=pmf.posteriors
         )
    )
end

function getCounts(v::Vec{T})::Dict{T,Int} where {T}
    result::Dict{T,Int} = Dict()
    for elt in v
        result[elt] = get(result, elt, 0) + 1
    end
    return result
end

function getPmfFromSeq(seq::Vec{T})::Pmf{T} where {T}
    counts::Dict{T,Int} = getCounts(seq)
    sortedKeys::Vec{T} = keys(counts) |> collect |> sort
    sortedVals::Vec{Int} = [counts[k] for k in sortedKeys]
    return Pmf(sortedKeys, sortedVals)
end

function getFieldValsEqName(pmf::Pmf{T}, name::T, fieldName::String, default) where {T}
    ind = findfirst(x -> x == name, getproperty(pmf, Symbol("names")))
    return isnothing(ind) ? default : getproperty(pmf, Symbol(fieldName))[ind]
end

function getPriorByName(pmf::Pmf{T}, name::T)::Float64 where {T}
    return getFieldValsEqName(pmf, name, "priors", 0.0)
end

function getPriorsByNames(pmf::Pmf{T}, names::Vec{T})::Vec{Float64} where {T}
    return map(n -> getPriorByName(pmf, n), names)
end

function setLikelihoods!(pmf::Pmf{T}, newLikelihoods::Vec{Float64})::Pmf{T} where {T}
    pmf.likelihoods = newLikelihoods
    return pmf
end

function setPosteriors!(pmf::Pmf{T}, newPosteriors::Vec{Float64})::Pmf{T} where {T}
    pmf.posteriors = newPosteriors
    return pmf
end

"""
        normalizes pmf.posteriors so they add up to 1
"""
function normalizePosteriors!(pmf::Pmf{T})::Pmf{T} where {T}
    pmf.posteriors = pmf.posteriors ./ sum(pmf.posteriors)
    return pmf
end

"""
        updates posteriors (priors .* likeliehoods)
        if normalize = true, then posteriors are normalized
"""
function bayesUpdate!(pmf::Pmf{T}, normalize::Bool)::Pmf{T} where {T}
    setPosteriors!(pmf, pmf.priors .* pmf.likelihoods)
    if normalize
        normalizePosteriors!(pmf)
    end
    return pmf
end

function getIndMaxField(pmf::Pmf, field::String)::Int
    maxProb::Float64 = max(getproperty(pmf, Symbol(field))...)
    return findfirst(x -> x == maxProb, getproperty(pmf, Symbol(field)))
end

function getIndMaxPosterior(pmf::Pmf)::Int
    return getIndMaxField(pmf, "posteriors")
end

function getIndMaxPrior(pmf::Pmf)::Int
    return getIndMaxField(pmf, "priors")
end

function getNameMaxPrior(pmf::Pmf{T})::T where {T}
    return pmf.names[getIndMaxPrior(pmf)]
end

function getNameMaxPosterior(pmf::Pmf{T})::T where {T}
    return pmf.names[getIndMaxPosterior(pmf)]
end

function updatePosteriors!(pmf::Pmf{<:Union{Flt, Int}},
                           nameThatOccurred::Union{Flt, Int})::Pmf{<:Union{Flt, Int}}
    hypos::Vec{<:Union{Flt, Int}} = pmf.names
    likelihoods::Vec{Flt} = 1 ./ hypos
    impossible::Bv = nameThatOccurred .> hypos
    likelihoods[impossible] .= 0.0
    setLikelihoods!(pmf, likelihoods)
    if all(pmf.posteriors .== 0) # posteriors are initialized with 0s
        return bayesUpdate!(pmf, true)
    else
        pmf.posteriors .*= pmf.likelihoods
        return normalizePosteriors!(pmf)
    end
end

function updatePosteriors!(pmf::Pmf{<:Union{Flt, Int}},
                           namesThatOccurred::Vec{<:Union{Flt, Int}})::Pmf{<:Union{Flt, Int}}
    foreach(n -> updatePosteriors!(pmf, n), namesThatOccurred)
    return pmf
end

function getBinomPmf(n::Int, p::Flt)::Pmf{Int}
    @assert n > 0 "n must be greater than 0"
    @assert 0 <= p <= 1 "p must be in the range [0-1]"
    binDst = Dst.Binomial(n, p)
    ks::Vec{Int} = c(0:n)
    return Pmf(ks, Dst.pdf.(binDst, ks))
end

function getTotalProbGeName(pmf::Pmf{T}, field::Str, name::T)::Flt where {T}
    isGe::Bv = pmf.names .>= name
    total::Flt = getproperty(pmf, Symbol(field))[isGe] |> sum
    return total
end

function getTotalProbLeName(pmf::Pmf{T}, field::Str, name::T)::Flt where {T}
    isLe::Bv = pmf.names .<= name
    total::Flt = getproperty(pmf, Symbol(field))[isLe] |> sum
    return total
end

function drawLinesPmf(pmf::Pmf{T},
    pmfFieldForYs::Str, title::Str, xlabel::Str, ylabel::Str)::Cmk.Figure where {T}
    fig = Cmk.Figure(size=(600, 400))
    Cmk.lines(fig[1, 1],
        pmf.names, getproperty(pmf, Symbol(pmfFieldForYs)), color="navy",
        axis=(;
            title=title,
            xlabel=xlabel,
            ylabel=ylabel,
        ))
    return fig

end

function drawPriors(pmf::Pmf{T}, title::Str, xlabel::Str, ylabel::Str)::Cmk.Figure where {T}
    return drawLinesPmf(pmf, "priors", title, xlabel, ylabel)
end

function drawPosteriors(pmf::Pmf{T}, title::Str, xlabel::Str, ylabel::Str)::Cmk.Figure where {T}
    return drawLinesPmf(pmf, "posteriors", title, xlabel, ylabel)
end

function updatePosteriors!(pmf::Pmf{<:Union{Flt, Int}},
                           events::Vec{A},
                           eventsProbs::Dict{A, Vec{Flt}})::Pmf{<:Union{Flt, Int}} where A
    pmf.likelihoods .= 1
    for e in events
        pmf.likelihoods .*= eventsProbs[e]
    end
    return bayesUpdate!(pmf, true)
end

function updateBinomial!(pmf::Pmf{<:Union{Flt, Int}}, k::Int, n::Int)::Pmf{<:Union{Flt, Int}}
    @assert n >= k >= 0 "n and k must be >= 0"
    xs::Vec{<:Union{Flt, Int}} = pmf.names
    likelihoods::Vec{Flt} = Dst.pdf.(Dst.Binomial.(n, xs), k)
    setLikelihoods!(pmf, likelihoods)
    return bayesUpdate!(pmf, true)
end

#+END_SRC

** other fns

#+BEGIN_SRC

function rep(x::A, times::Int)::Vec{A} where A
    @assert times > 1 "times must be greater than 1"
    return [x for _ in 1:times]
end

function rep(v::Vec{A}, times::Vec{Int})::Vec{A} where A
    @assert (len(v) == len(times)) "length(v) not equal length(times)"
    @assert all(map((>)(0), times)) "times elts must be GT 0"
    result::Vec{A} = Vec{eltype(v)}(undef, sum(times))
    currInd::Int = 1
    for i in eachindex(v)
        for _ in 1:times[i]
            result[currInd] = v[i]
            currInd += 1
        end
    end
    return result
end

c(sth) = collect(sth)
str(sth) = string(sth)

#+END_SRC

* 4.1. The Euro Problem

In Information Theory, Inference, and Learning Algorithms, David MacKay poses this problem:

“A statistical statement appeared in The Guardian on Friday January 4, 2002:

When spun on edge 250 times, a Belgian one-euro coin came up heads 140 times and tails 110. `It looks very suspicious to me,’ said Barry Blight, a statistics lecturer at the London School of Economics. `If the coin were unbiased, the chance of getting a result as extreme as that would be less than 7%.’

“But [MacKay asks] do these data give evidence that the coin is biased rather than fair?”

* 4.2. The Binomial Distribution

Fair coin toss. n - num. of coin tosses, p - prob of success in a single toss,
k - num. of successes in all coin tosses.

#+BEGIN_SRC

n = 2
p = 0.5
k = 1

binDst = Dst.Binomial(n, p)
Dst.pdf(binDst, k) |> round3

#+END_SRC

Another example.

#+BEGIN_SRC

ks = 0:n

Dst.pdf.(binDst, 0:n) .|> round3

#+END_SRC

To automate it we use `getBinomPmf` defined earlier.

#+BEGIN_SRC

coin = getBinomPmf(250, 0.5)

drawPriors(coin,
           "Binomial distribution (n=250, p=0.5)",
           "Number of heads (k)",
           "PMF")

#+END_SRC

Most likely number of heads (and its probability) is:

#+BEGIN_SRC

ind = getIndMaxPrior(coin)
coin.names[ind], coin.priors[ind]

#+END_SRC

In MacKay's example, we got 140 heads, with probability of:

#+BEGIN_SRC

ind = findfirst((==)(140), coin.names)
coin.priors[ind]

#+END_SRC


MacKay says: the chance of getting a result as extreme as that would be 7%.
Let's see if that's true.

#+BEGIN_SRC

# two tail, so: >= 140 && <= 110
getTotalProbGeName(coin, "priors", 140) + getTotalProbLeName(coin, "priors", 110)

#+END_SRC

* 4.3. Bayesian Estimation

Probability of a coin landing heads.

#+BEGIN_SRC

coin = getPmfFromSeq(c(0:0.01:1))

#+END_SRC

Likelihoods for heads and tails for each coin

#+BEGIN_SRC

likelihood = Dict('h' => coin.names, 't' => 1 .- coin.names)
# 140 h out of 250 tosses (see 4.1.)
cointosses = rep(['h', 't'], [140, 110])

#+END_SRC

Bayesian update for binomial distribution.

#+BEGIN_SRC

# defined in the Pmf section above
updatePosteriors!(coin, cointosses, likelihood)

#+END_SRC

Drawing of posteriors after the update.

#+BEGIN_SRC

drawPosteriors(coin,
               "Posterior distribution of #of heads\n(140 h out of 250 tosses)",
               "Probability", "Proportion of heads")

#+END_SRC

What real proportion of heads for the coin is most likely:

#+BEGIN_SRC

indMax = getIndMaxPosterior(coin)
coin.names[indMax]

#+END_SRC

* 4.4. Triangle Prior
Previously we tried triangle prior, this time we'll go with quite a different beast.

#+BEGIN_SRC

uniform = getPmfFromSeq(c(0:0.01:1))
triangle = Pmf(c(0:0.01:1), [0:49..., 50:-1:0...])

#+END_SRC

Next, we draw the priors.

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], title="Uniform and triangle prior distributions",
         xlabel="Proportion of heads (x)", ylabel="Probability");
Cmk.lines!(ax, uniform.names, uniform.priors, label="uniform");
Cmk.lines!(ax, triangle.names, triangle.priors, label="triangle");
Cmk.axislegend();
fig

#+END_SRC

Let's do the update and see do the posteriors differ.

#+BEGIN_SRC

updatePosteriors!(uniform, cointosses, likelihood)
updatePosteriors!(triangle, cointosses, likelihood)

#+END_SRC

And the drawing.

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], title="Uniform and triangle posterior distributions",
         xlabel="Proportion of heads (x)", ylabel="Probability");
Cmk.lines!(ax, uniform.names, uniform.posteriors, label="uniform");
Cmk.lines!(ax, triangle.names, triangle.posteriors, label="triangle");
Cmk.axislegend();
fig

#+END_SRC

With enough data for likelihoods and Bayesian update we land with almost
identical posteriors. Yay.

* 4.5. The Binomial Likelihood Function

Instead of computing update one coin spin at a time (for 250 spins) we can do
this all at one with the following formula:

$ \binom{n}{k}*p^{k}*(1-p)^{n-k }$

where:

n - total number of tosses

p - probability of success in a single toss

k - number of successes

We can implement this formula into code (see this file Pmf > helper fns) and use
it for the update.

#+BEGIN_SRC

uniform2 = getPmfFromSeq(c(0:0.01:1))
updateBinomial!(uniform2, 140, 250)

#+END_SRC

The result should be the same like the previously defined `uniform`.

#+BEGIN_SRC

isapprox.(uniform.names, uniform2.names) |> all
isapprox.(uniform.priors, uniform2.priors) |> all
isapprox.(uniform.posteriors, uniform2.posteriors) |> all

#+END_SRC

Although the calculations should be more efficient.

* 4.6. Bayesian Statistics

By comparing the Euro and 101 Bowls problem (from a previous chapter) you might
notice that the choice of priors is often subjective (different people may choose
different values). Because of that the posteriors are subjective too.

Historically, many have been bothered by its subjectivity and its use of
probability for things that are not random (like physical quantities of the
coins).

* 4.7. Summary

Even when we start with two different priors, then given enough data they tend
to converge and give similar posteriors.

Overall, the chapter was interesting, but we still haven't answered MacKay's
question: "Do these data give evidence that the coin is biased rather than
fair?" The question will be answered in Testing (chapter 10).

* 4.8. Exercises
** 4.8.1. Exercise 1
 In Major League Baseball, most players have a batting average between .200 and
 .330, which means that their probability of getting a hit is between 0.2 and
 0.33.

 Suppose a player appearing in their first game gets 3 hits out of 3 attempts.
 What is the posterior distribution for their probability of getting a hit?

 Start with the following priors.

#+BEGIN_SRC

# names of the hypothesis: true hit rates
trueHitRates = range(0.1, 0.4, 101) |> c
batting = getPmfFromSeq(trueHitRates)
likelihood = Dict('y' => trueHitRates, 'n' => 1 .- trueHitRates)
# dataset that yields a reasonable prior distribution
dataset = rep(['y', 'n'], [25, 75])
# update with the imaginary data
updatePosteriors!(batting, dataset, likelihood)
# draw priors
drawPosteriors(batting, "Baseball, avg hits priors", "Probability of getting a it", "PMF")

# set the result as priors, initialize with 0s the rest
batting.priors = copy(batting.posteriors)
batting.likelihoods .= 0
batting.posteriors .= 0

#+END_SRC

Now update this distribution with the data and plot the posterior. What is the
most likely quantity in the posterior distribution?

*** Solution 1

Update.

#+BEGIN_SRC

dataset = rep('y', 3)
updatePosteriors!(batting, dataset, likelihood)

#+END_SRC

Drawing Comparison.

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Probability of getting a hit", ylabel="PMF");
Cmk.lines!(ax, batting.names, batting.priors, label="prior");
Cmk.lines!(ax, batting.names, batting.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC

Numerical comparison.

#+BEGIN_SRC

maxPriorInd = getIndMaxPrior(batting)
batting.names[maxPriorInd], batting.posteriors[maxPriorInd]

maxPostInd = getIndMaxPosterior(batting)
batting.names[maxPostInd], batting.posteriors[maxPostInd]

#+END_SRC

*** Solution 2

Starting with priors set like in the chapter.

Update.

#+BEGIN_SRC

updateBinomial!(batting, 3, 3)

#+END_SRC

Drawing Comparison.

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Probability of getting a hit", ylabel="PMF");
Cmk.lines!(ax, batting.names, batting.priors, label="prior");
Cmk.lines!(ax, batting.names, batting.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC

Numerical comparison.

#+BEGIN_SRC

maxPriorInd = getIndMaxPrior(batting)
batting.names[maxPriorInd], batting.posteriors[maxPriorInd]

maxPostInd = getIndMaxPosterior(batting)
batting.names[maxPostInd], batting.posteriors[maxPostInd]

#+END_SRC

** 4.8.2. Exercise 2

Suppose you want to know how many people cheat on their taxes. If you ask them
directly, it is likely that some of the cheaters will lie. You can get a more
accurate estimate if you ask them indirectly, like this: Ask each person to flip
a coin and, without revealing the outcome,

If they get heads, they report YES.

If they get tails, they honestly answer the question “Do you cheat on your
taxes?”

If someone says YES, we don’t know whether they actually cheat on their taxes;
they might have flipped heads. Knowing this, people might be more willing to
answer honestly.

Suppose you survey 100 people this way and get 80 YESes and 20 NOs. Based on
this data, what is the posterior distribution for the fraction of people who
cheat on their taxes? What is the most likely quantity in the posterior
distribution?

Pmf definition.

#+BEGIN_SRC

cheatingProbs = range(0, 1, 101) |> c
taxes = getPmfFromSeq(cheatingProbs)

#+END_SRC

*** Solution 1

Dataset:

#+BEGIN_SRC

# result, but 50 y are due to the coin toss
dataset = rep(['y', 'n'], [80, 20])

#+END_SRC

Let's say 50% of people cheat and 50% do not. If so, then on every 100 individuals:

- 50 will say they cheat because of the coin (25 real cheaters, 25 non-cheaters)
- of the remaining 50: 25 will say they cheated (real cheaters), 25 will say they did not cheat (real non-cheaters)

Therefore, the probability that a person says they cheat is:

0.5 (coin prob) + prob real cheaters - prob real cheaters * coin prob

We can put in into a function:

#+BEGIN_SRC

function getCorrectedProbCheating(probCheating::Flt, biasProb::Flt)::Flt
    @assert 0 <= probCheating <= 1 "probCheating must be in range [0-1]"
    @assert 0 <= biasProb <= 1 "biasProb must be in range [0-1]"
    return biasProb + probCheating - probCheating * biasProb
end

function getCorrectedProbHonest(probCheating::Flt, biasProb::Flt)::Flt
    return 1 - getCorrectedProbCheating(probCheating, biasProb)
end

#+END_SRC

And do the update.

#+BEGIN_SRC

likelihood = Dict('y' => getCorrectedProbCheating.(cheatingProbs, 0.5),
                  'n' => getCorrectedProbHonest.(cheatingProbs, 0.5))
updatePosteriors!(taxes, dataset, likelihood)

#+END_SRC

Now, we may draw a comparison:

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Probability of cheating on taxes", ylabel="PMF");
Cmk.lines!(ax, taxes.names, taxes.priors, label="prior");
Cmk.lines!(ax, taxes.names, taxes.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC

and do a numerical assessment:

#+BEGIN_SRC

maxPostInd = getIndMaxPosterior(taxes)
taxes.names[maxPostInd], taxes.posteriors[maxPostInd]

#+END_SRC

*** Solution 2

Starting with priors set like before.

Update.

#+BEGIN_SRC

updateBinomial!(taxes, 80-50, 80+20-50)

#+END_SRC

Drawing Comparison.

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Probability of cheating on taxes", ylabel="PMF");
Cmk.lines!(ax, taxes.names, taxes.priors, label="prior");
Cmk.lines!(ax, taxes.names, taxes.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC

Numerical assessment.

#+BEGIN_SRC

maxPostInd = getIndMaxPosterior(taxes)
taxes.names[maxPostInd], taxes.posteriors[maxPostInd]

#+END_SRC

** 4.8.3. Exercise 3

Suppose you want to test whether a coin is fair, but you don’t want to spin it
hundreds of times. So you make a machine that spins the coin automatically and
uses computer vision to determine the outcome.

However, you discover that the machine is not always accurate. Specifically,
suppose the probability is y=0.2 that an actual heads is reported as tails, or
actual tails reported as heads.

If we spin a coin 250 times and the machine reports 140 heads, what is the
posterior distribution of x? What happens as you vary the value of y?

#+BEGIN_SRC

headProbs = range(0, 1, 101) |> c
coinMachine = getPmfFromSeq(headProbs)

#+END_SRC

Let's say we got a fair coin P(heads = 0.5), then what is a probability of
getting heads with biased computer vision [P(heads|bias) or P(D|H)]?

Out of 1000 tosses I should get:
- 500 real heads (20%, so 100 misclassified as tails)
- 500 real tails (20%, so 100 misclassified as heads)

Which yields:
- 400 real heads plus 100 false heads
- 400 real tails plus 100 false tails

where:
- P(real head) = P(real head) and P(no classification bias)
- P(real tail) = P(real tail) and P(no classification bias)
- P(false head) = P(real tail) and P(classification bias)
- P(false tail) = P(real head) and P(classification bias)

So:

P(heads|bias) = P(heads) * P(no bias) + P(tails) * P(bias)

P(tails|bias) = P(tails) * P(no bias) + P(heads) * P(bias)

Let's transform the last two formulas into functions.

#+BEGIN_SRC

function getCorrectedPheads(pHeads::Flt, pBias::Flt)::Flt
    @assert 0 <= pHeads <= 1 "pHeads must be in range [0-1]"
    @assert 0 <= pBias <= 1 "pBias must be in range [0-1]"
    return pHeads * (1-pBias) + (1-pHeads) * pBias
end

function getCorrectedPtails(pHeads::Flt, pBias::Flt)::Flt
    return getCorrectedPheads(1-pHeads, pBias)
end

#+END_SRC

Now, for datasets and likelihoods.

#+BEGIN_SRC

dataset = rep(['h', 't'], [140, 250-140])
likelihood = Dict(
    'h' => getCorrectedPheads.(headProbs, 0.2),
    't' => getCorrectedPtails.(headProbs, 0.2))

#+END_SRC

Which we use to update posteriors:

#+BEGIN_SRC

updatePosteriors!(coinMachine, dataset, likelihood)

#+END_SRC

draw comparisons:

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Probability of getting a head", ylabel="PMF");
Cmk.lines!(ax, coinMachine.names, coinMachine.priors, label="prior");
Cmk.lines!(ax, coinMachine.names, coinMachine.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC

and to perform numerical assessment:

#+BEGIN_SRC

maxPostInd = getIndMaxPosterior(coinMachine)
coinMachine.names[maxPostInd], coinMachine.posteriors[maxPostInd]

#+END_SRC

Different values of y, i.e. prob. of misclassification:

#+BEGIN_SRC

headProbs = range(0, 1, 101) |> c
dataset = rep(['h', 't'], [140, 250-140])
fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1], xlabel="Posterior probability of getting heads", ylabel="PMF");

for pError in 0:0.1:0.4
    coinMachine = getPmfFromSeq(headProbs);
    likelihood = Dict(
        'h' => getCorrectedPheads.(headProbs, pError),
        't' => getCorrectedPtails.(headProbs, pError));
    updatePosteriors!(coinMachine, dataset, likelihood);
    Cmk.lines!(ax, coinMachine.names, coinMachine.posteriors,
               label="pError = $pError");
    maxPostInd = getIndMaxPosterior(coinMachine);
    maxPostName = coinMachine.names[maxPostInd];
    maxPostProb = coinMachine.posteriors[maxPostInd] |> round3;
    Cmk.text!(0, maxPostProb, text="maxPost = $maxPostName, prob = $maxPostProb");
end

Cmk.axislegend();
fig

#+END_SRC

** 4.8.4. Exercise 4

In preparation for an alien invasion, the Earth Defense League (EDL) has been
working on new missiles to shoot down space invaders. Of course, some missile
designs are better than others; let’s assume that each design has some
probability of hitting an alien ship, x.

Based on previous tests, the distribution of x in the population of designs is
approximately uniform between 0.1 and 0.4.

Now suppose the new ultra-secret Alien Blaster 9000 is being tested. In a press
conference, an EDL general reports that the new design has been tested twice,
taking two shots during each test. The results of the test are confidential, so
the general won’t say how many targets were hit, but they report: “The same
number of targets were hit in the two tests, so we have reason to think this new
design is consistent.”

Is this data good or bad? That is, does it increase or decrease your estimate of
x for the Alien Blaster 9000?

Hint: If the probability of hitting each target is x, the probability of hitting
one target in both tests is $[2*x*(1-x)]^2$

*** Reasoning

My explanation for the probability of getting the same number of hits in both tests, based on properties of probability from [[https://b-lukaszuk.github.io/RJ_BS_eng/statistics_intro_probability_properties.html][here]]:

During a test with two shots I can have one of the following results (H - hit, M - miss):

- HH, HM, MH, MM

The same number of shots in both tests means either of:

- 00, 11, 22,

If we assume:

- x - probability of hitting a target,
- y - probability of not hitting a target (1 - x)

then:

Probability of hitting 0 shots in two tests [P(MM) AND P(MM)] is:

- y * y (first test),
- y * y (second test)

In total (2 tests): y * y * y * y = $y^4$ = $(1-x)^4$

Probability of hitting 1 shot in two tests, i.e.:

- P(HM) OR P(MH) [first test]
  AND
- P(HM) OR P(MH) [second test] is:

- x * y + y * x => xy + xy (multiplication commutativity) => 2xy (first test),
- x * y + y * x => xy + xy (multiplication commutativity) => 2xy (second test),

In total (2 tests): 2xy * 2xy = 4*xx*yy = $4x^2*y^2$ => $4x^2*(1-x)^2$

This could be rewritten as: $[2x*(1-x)]^2$ (from the author's hint above)

Probability of hitting 2 shots in two tests [P(HH) AND P(HH)] is:

- x * x => $x^2$ (first test),
- x * x => $x^2$ (second test)

In total (2 tests): x * x * x * x = $x^4$

So, the probability of getting the same result in two tests is:

- P(0 & 0) + P(1 & 1) + P(2 & 2) = $[(1-x)^4] + [4x^2*(1-x)^2] + [x^4]$

*** Solution

PMF object:

#+BEGIN_SRC

alienHitProbs = range(0.1, 0.4, 101) |> c
edl = getPmfFromSeq(alienHitProbs)

#+END_SRC

Formula for likelihoods:

#+BEGIN_SRC

# based on the reasoning given above
function getLikelihoodHit(pHit::Flt)::Flt
    @assert 0 <= pHit <= 1 "pHit must be in range [0-1]"
    p00::Flt = (1-pHit)^4
    p11::Flt = (4*pHit^2) * (1-pHit)^2
    p22::Flt = pHit^4
    return p00 + p11 + p22
end

#+END_SRC

Bayesian update:

#+BEGIN_SRC

setLikelihoods!(edl, getLikelihoodHit.(edl.names))
bayesUpdate!(edl, true)

#+END_SRC

Graphical display:

#+BEGIN_SRC

fig = Cmk.Figure();
ax = Cmk.Axis(fig[1, 1],
              title="Alien Blaster 9000\nSame number of targets hit in both tests",
              xlabel="Probability of hitting an alien ship", ylabel="PMF");
Cmk.lines!(ax, edl.names, edl.priors, label="prior");
Cmk.lines!(ax, edl.names, edl.posteriors, label="posterior");
Cmk.axislegend();
fig

#+END_SRC
