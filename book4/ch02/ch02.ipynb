{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e968d5",
   "metadata": {},
   "source": [
    "# Chapter 2. Bayes's Theorem\n",
    "[Link to chapter online](https://allendowney.github.io/ThinkBayes2/chap02.html)\n",
    "\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350a5e3",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "The content of this file may be incorrect, erroneous and/or harmful. Use it at Your own risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e42113",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f34f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataFrames as Dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5f5b6",
   "metadata": {},
   "source": [
    "## Functionality developed in this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    update!(df)\n",
    "    \n",
    "Compute the posterior probabilities\n",
    "\n",
    "# Arguments\n",
    "- df: Dfs.DataFrame, must contain columns named: prior, likelihood\n",
    "\"\"\"\n",
    "function update!(df::Dfs.DataFrame)\n",
    "    df.unnorm = df.prior .* df.likelihood\n",
    "    df.posterior = df.unnorm ./ sum(df.unnorm)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4449ea0",
   "metadata": {},
   "source": [
    "## The Cookie Problem\n",
    "\n",
    "Suppose there are two bowls of cookies.\n",
    "- Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.\n",
    "- Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.\n",
    "\n",
    "Now suppose you choose one of the bowls at random and, without looking, choose a cookie at random. If the cookie is vanilla, what is the probability that it came from Bowl 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443881bd",
   "metadata": {},
   "source": [
    "My (BL) logical reasoning:\n",
    "- fact: I got vanilla cookie\n",
    "- vanilla cookies in total (B1 + B2) = (30+20) = 50\n",
    "- prob of getting white cookie from bowl1 = $\\frac{30}{50}$ = 0.6\n",
    "\n",
    "The calculations above work because both bowls got equal number of cookies (40 in each).\n",
    "\n",
    "Using Bayese's Theorem:\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is $P(B1|Vanilla)$\n",
    "- $P(A)$ is $P(B1)$ = $\\frac{1}{2}$\n",
    "- $P(B|A)$ is $P(Vanilla|B1)$ = $\\frac{30}{40}$ = $\\frac{3}{4}$\n",
    "- $P(B)$ is $P(Vanilla)$ = $\\frac{30+20}{40+40}$ = $\\frac{50}{80}$ = $\\frac{5}{8}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{\\frac{1}{2} * \\frac{3}{4}}{\\frac{5}{8}}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{\\frac{3}{8}}{\\frac{5}{8}}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{3}{8} * \\frac{8}{5}$ (to divide is to multiply by inverse)\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{24}{40} = \\frac{24/4}{40/4}= \\frac{6}{10} = 0.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cef71",
   "metadata": {},
   "source": [
    "## Diachronic Bayes\n",
    "\n",
    "\"diachronic\" means \"related to change over time\"; in this case the probability of the hypotheses changes as we see new data.\n",
    "\n",
    "Rewriting Bayese's Theorem, from:\n",
    "\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$\n",
    "\n",
    "replacements:\n",
    "A = H (hypothesis), B = D (new data)\n",
    "\n",
    "new form:\n",
    "\n",
    "$P(H|D) = \\frac{P(H)P(D|H)}{P(D)}$, where\n",
    "\n",
    "- P(H) - probability of the hypothesis before we see data, **prior**\n",
    "- P(H|D) - probability of the hypothesis after we see data, **posterior**\n",
    "- P(D|H) - probability of the data under the hypothesis, **likelihood**\n",
    "- P(D) - the total probability of the data under the hypothesis\n",
    "\n",
    "We can compute $P(D)$ using the law of total probability (from ch01):\n",
    "\n",
    "$P(A) = P(B_1\\ and\\ A) + P(B_2\\ and\\ A) + ...$\n",
    "\n",
    "And Theorem 2 [remember: $P(A\\ and\\ B) = P(B\\ and\\ A)$ (multiplication is cumutative)]:\n",
    "\n",
    "$P(A\\ and\\ B) = P(B)P(A|B)$\n",
    "\n",
    "After applying Theorem 2 to the law of total probability we get:\n",
    "\n",
    "$P(A) = P(B_1)P(A|B_1) + P(B_2)P(A|B_2) + ...$\n",
    "\n",
    "If we replace:\n",
    "- A with D,\n",
    "- B with H\n",
    "\n",
    "We get:\n",
    "\n",
    "Here rewritten as:\n",
    "\n",
    "$P(D) = \\sum_iP(H_i)~P(D|H_i)$\n",
    "\n",
    "The process in this section, using data and a prior probability to compute a posterior probability, is called a **Bayesian update**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195a896",
   "metadata": {},
   "source": [
    "## Bayes Tables\n",
    "\n",
    "A convenient tool for doing a bayesian update is a Bayes table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02243adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Dfs.DataFrame(\n",
    "    (;\n",
    "    names=[\"Bowl1\", \"Bowl2\"],\n",
    "    prior=[0.5, 0.5], # prob get a bowl (1/2 and 1/2)\n",
    "    # prob get vanilla cookie for a bowl (30/40 and 20/40)\n",
    "    likelihood=[0.75, 0.5]) \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ee167",
   "metadata": {},
   "source": [
    "You might notice that the likelihoods don’t add up to 1. That’s OK; each of them is a probability conditioned on a different hypothesis. There’s no reason they should add up to 1 and no problem if they don’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837375fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnorm = P(D) = P(B_i) * P(D|B_i) = P(H_i) * P(D|H_i)\n",
    "# see: numerator in The Cookie Problem\n",
    "table.unnorm = table.prior .* table.likelihood\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(D) = \\sum_iP(H_i) * P(D|H_i)\n",
    "# denominator in The Cookie Problem ((30+20)/(40+40) = 50/80 = 5/8)\n",
    "probData = sum(table.unnorm)\n",
    "probData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# ((3/8)/(5/8)) = 24/40 = 6/10 = 0.6 (division in The Cookie Problem)\n",
    "# ((1/4)/(5/8)) = 1/4 * 8/5 = 2/5 = 0.4 (not performed in The Cookie Problem)\n",
    "table.posterior = table.unnorm ./ probData\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a67fca",
   "metadata": {},
   "source": [
    "## The Dice Problem\n",
    "\n",
    "A Bayes table can also solve problems with more than two hypotheses. For example:\n",
    "\n",
    "> Suppose I have a box with a 6-sided die, an 8-sided die, and a 12-sided die. I choose one of the dice at random, roll it, and report that the outcome is a 1. What is the probability that I chose the 6-sided die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = Dfs.DataFrame(\n",
    "    (;\n",
    "    qs=[6, 8, 12],\n",
    "    prior=repeat([1//3], 3),\n",
    "    likelihood=[1//6, 1//8, 1//12]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update!(table2)\n",
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702155b",
   "metadata": {},
   "source": [
    "## The Monty Hall Problem \n",
    "\n",
    "The Monty Hall problem is based on a game show called 'Let’s Make a Deal'. If you are a contestant on the show, here’s how the game works:\n",
    "- The host, Monty Hall, shows you three closed doors – numbered 1, 2, and 3 – and tells you that there is a prize behind each door.\n",
    "- One prize is valuable (traditionally a car), the other two are less valuable (traditionally goats).\n",
    "- The object of the game is to guess which door has the car. If you guess right, you get to keep the car.\n",
    "\n",
    "Suppose you pick Door 1. Before opening the door you chose, Monty opens Door 3 and reveals a goat. Then Monty offers you the option to stick with your original choice or switch to the remaining unopened door.\n",
    "\n",
    "To maximize your chance of winning the car, should you stick with Door 1 or switch to Door 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e80ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3 = Dfs.DataFrame(\n",
    "    (;\n",
    "    qs=[1, 2, 3],\n",
    "    prior=[1//3, 1//3, 1//3],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89d531",
   "metadata": {},
   "source": [
    "The data is that Monty opened Door 3 and revealed a goat. So let’s consider the probability of the data under each hypothesis:\n",
    "- If the car is behind Door 1, Monty chooses Door 2 or 3 at random, so the probability he opens Door 3 is $1/2$.\n",
    "- If the car is behind Door 2, Monty has to open Door 3, so the probability of the data under this hypothesis is 1.\n",
    "- If the car is behind Door 3, Monty does not open it, so the probability of the data under this hypothesis is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table3.likelihood = [1//2, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "update!(table3)\n",
    "table3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d9bcc",
   "metadata": {},
   "source": [
    "As this example shows, our intuition for probability is not always reliable. Bayes’s Theorem can help by providing a divide-and-conquer strategy:\n",
    "- First, write down the hypotheses and the data.\n",
    "- Next, figure out the prior probabilities.\n",
    "- Finally, compute the likelihood of the data under each hypothesis.\n",
    "\n",
    "The Bayes table does the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4d75f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The Bayes table can make it easier to compute the total probability of the data, especially for problems with more than two hypotheses.\n",
    "\n",
    "Now, go to some exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14541c3f",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651aa61",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Suppose you have two coins in a box. One is a normal coin with heads on one side and tails on the other, and one is a trick coin with heads on both sides. You choose a coin at random and see that one of the sides is heads. What is the probability that you chose the trick coin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429be642",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = Dfs.DataFrame(\n",
    "    (;\n",
    "    coins=[\"HT\", \"HH\"],\n",
    "    prior=[1//2, 1//2],\n",
    "    likelihood=[1//2, 1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f715ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "update!(ex1)\n",
    "ex1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
