{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e968d5",
   "metadata": {},
   "source": [
    "# Chapter 2. Bayes's Theorem\n",
    "[Link to chapter online](https://allendowney.github.io/ThinkBayes2/chap02.html)\n",
    "\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350a5e3",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "The content of this file may be incorrect, erroneous and/or harmful. Use it at Your own risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e42113",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f34f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataFrames as Dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5f5b6",
   "metadata": {},
   "source": [
    "## Functionality developed in this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    update!(df)\n",
    "    \n",
    "Compute the posterior probabilities\n",
    "\n",
    "# Arguments\n",
    "- df: Dfs.DataFrame, must contain columns named: prior, likelihood\n",
    "\"\"\"\n",
    "function update!(df::Dfs.DataFrame)\n",
    "    df.unnorm = df.prior .* df.likelihood\n",
    "    df.posterior = df.unnorm ./ sum(df.unnorm)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4449ea0",
   "metadata": {},
   "source": [
    "## The Cookie Problem\n",
    "\n",
    "Suppose there are two bowls of cookies.\n",
    "- Bowl 1 contains 30 vanilla cookies and 10 chocolate cookies.\n",
    "- Bowl 2 contains 20 vanilla cookies and 20 chocolate cookies.\n",
    "\n",
    "Now suppose you choose one of the bowls at random and, without looking, choose a cookie at random. If the cookie is vanilla, what is the probability that it came from Bowl 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443881bd",
   "metadata": {},
   "source": [
    "My (BL) logical reasoning:\n",
    "- fact: I got vanilla cookie\n",
    "- vanilla cookies in total (B1 + B2) = (30+20) = 50\n",
    "- prob of getting white cookie from bowl1 = $\\frac{30}{50}$ = 0.6\n",
    "\n",
    "Using Bayese's Theorem:\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$\n",
    "\n",
    "Where:\n",
    "- $P(A|B)$ is $P(B1|Vanilla)$\n",
    "- $P(A)$ is $P(B1)$ = $\\frac{1}{2}$\n",
    "- $P(B|A)$ is $P(Vanilla|B1)$ = $\\frac{30}{40}$ = $\\frac{3}{4}$\n",
    "- $P(B)$ is $P(Vanilla)$ = $\\frac{30+20}{40+40}$ = $\\frac{50}{80}$ = $\\frac{5}{8}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{\\frac{1}{2} * \\frac{3}{4}}{\\frac{5}{8}}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{\\frac{3}{8}}{\\frac{5}{8}}$\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{3}{8} * \\frac{8}{5}$ (to divide is to multiply by inverse)\n",
    "\n",
    "$P(B1|Vanilla) = \\frac{24}{40} = \\frac{24/4}{40/4}= \\frac{6}{10} = 0.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cef71",
   "metadata": {},
   "source": [
    "## Diachronic Bayes\n",
    "\n",
    "\"diachronic\" means \"related to change over time\"; in this case the probability of the hypotheses changes as we see new data.\n",
    "\n",
    "Rewriting Bayese's Theorem, from:\n",
    "\n",
    "$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$\n",
    "\n",
    "replacements:\n",
    "A = H (hypothesis), B = D (new data)\n",
    "\n",
    "new form:\n",
    "\n",
    "$P(H|D) = \\frac{P(H)P(D|H)}{P(D)}$, where\n",
    "\n",
    "- P(H) - probability of the hypothesis before we see data, **prior**\n",
    "- P(H|D) - probability of the hypothesis after we see data, **posterior**\n",
    "- P(D|H) - probability of the data under the hypothesis, **likelihood*\n",
    "- P(D) - the total probability of the data under the hypothesis\n",
    "\n",
    "We can compute $P(D)$ using the law of total probability (from ch01):\n",
    "\n",
    "$P(A) = P(B_1\\ and\\ A) + P(B_2\\ and\\ A) + ...$\n",
    "\n",
    "And Theorem 2 [remember: $P(A\\ and\\ B) = P(B\\ and\\ A)$ (multiplication is cumutative)]:\n",
    "\n",
    "$P(A\\ and\\ B) = P(B)P(A|B)$\n",
    "\n",
    "After applying Theorem 2 to the law of total probability we get:\n",
    "\n",
    "$P(A) = P(B_1)P(A|B_1) + P(B_2)P(A|B_2) + ...$\n",
    "\n",
    "If we replace:\n",
    "- A with D,\n",
    "- B with H\n",
    "\n",
    "We get:\n",
    "\n",
    "Here rewritten as:\n",
    "\n",
    "$P(D) = \\sum_iP(H_i)~P(D|H_i)$\n",
    "\n",
    "The process in this section, using data and a prior probability to compute a posterior probability, is called a **Bayesian update**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195a896",
   "metadata": {},
   "source": [
    "## Bayes Tables\n",
    "\n",
    "A convenient tool for doing a bayesian update is a Bayes table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02243adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Dfs.DataFrame(\n",
    "    (;\n",
    "    names=[\"Bowl1\", \"Bowl2\"],\n",
    "    prior=[0.5, 0.5], # prob get a bowl (1/2 and 1/2)\n",
    "    # prob get vanilla cookie for a bowl (30/40 and 20/40)\n",
    "    likelihood=[0.75, 0.5]) \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ee167",
   "metadata": {},
   "source": [
    "You might notice that the likelihoods don’t add up to 1. That’s OK; each of them is a probability conditioned on a different hypothesis. There’s no reason they should add up to 1 and no problem if they don’t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837375fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnorm = P(D) = P(B_i) * P(D|B_i) = P(H_i) * P(D|H_i)\n",
    "# see: numerator in The Cookie Problem\n",
    "table.unnorm = table.prior .* table.likelihood\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f8f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(D) = \\sum_iP(H_i) * P(D|H_i)\n",
    "# denominator in The Cookie Problem ((30+20)/(40+40) = 50/80 = 5/8)\n",
    "probData = sum(table.unnorm)\n",
    "probData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafcea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# ((3/8)/(5/8)) = 24/40 = 6/10 = 0.6 (division in The Cookie Problem)\n",
    "# ((1/4)/(5/8)) = 1/4 * 8/5 = 2/5 = 0.4 (not performed in The Cookie Problem)\n",
    "table.posterior = table.unnorm ./ probData\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a67fca",
   "metadata": {},
   "source": [
    "## The Dice Problem\n",
    "\n",
    "A Bayes table can also solve problems with more than two hypotheses. For example:\n",
    "\n",
    "> Suppose I have a box with a 6-sided die, an 8-sided die, and a 12-sided die. I choose one of the dice at random, roll it, and report that the outcome is a 1. What is the probability that I chose the 6-sided die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = Dfs.DataFrame(\n",
    "    (;\n",
    "    qs=[6, 8, 12],\n",
    "    prior=repeat([1//3], 3),\n",
    "    likelihood=[1//6, 1//8, 1//12]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update!(table2)\n",
    "table2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
